{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from threading import Thread  # needed since the denoiser is running in parallel\n",
    "import queue\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from models.skip import skip  # our network\n",
    "\n",
    "from utils.utils import *  # auxiliary functions\n",
    "from utils.mine_blur_utils2 import *  # blur functions\n",
    "from utils.data import Data  # class that holds img, psnr, time\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from skimage.restoration import denoise_nl_means\n",
    "\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# got GPU? - if you are not getting the exact article results set CUDNN to False\n",
    "CUDA_FLAG = True\n",
    "CUDNN = True \n",
    "if CUDA_FLAG:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    # GPU accelerated functionality for common operations in deep neural nets\n",
    "    torch.backends.cudnn.enabled = CUDNN\n",
    "    # benchmark mode is good whenever your input sizes for your network do not vary.\n",
    "    # This way, cudnn will look for the optimal set of algorithms for that particular \n",
    "    # configuration (which takes some time). This usually leads to faster runtime.\n",
    "    # But if your input sizes changes at each iteration, then cudnn will benchmark every\n",
    "    # time a new size appears, possibly leading to worse runtime performances.\n",
    "    torch.backends.cudnn.benchmark = CUDNN\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ],
   "id": "dcf55f7e48368601"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "NOISE_SIGMA = 5\n",
    "STD_BLUR    = 1.6\n",
    "DIM_FILTER  = 21\n",
    "BLUR_TYPE = 'gauss_blur'  # 'gauss_blur' or 'uniform_blur' that the two only options\n",
    "GRAY_SCALE = False  # if gray scale is False means we have rgb image, the psnr will be compared on Y. ch.\n",
    "                    # if gray scale is True it will turn rgb to gray scale\n",
    "USE_FOURIER = False\n",
    "\n",
    "# graphs labels:\n",
    "X_LABELS = ['Iterations']*3\n",
    "Y_LABELS = ['PSNR between x and net (db)', 'PSNR with original image (db)', 'loss']\n",
    "\n",
    "# Algorithm NAMES (to get the relevant image: use data_dict[alg_name].img)\n",
    "# for example use data_dict['Clean'].img to get the clean image\n",
    "ORIGINAL  = 'Clean'\n",
    "CORRUPTED = 'Blurred'\n",
    "DIP_NLM   = 'DIP-TTGV'"
   ],
   "id": "db00cb5e3ed4f713"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def rgb2yuv(rgb):\n",
    "    \"\"\"\n",
    "    将RGB图像转换为YUV颜色空间\n",
    "    \n",
    "    参数:\n",
    "    rgb: RGB图像，形状为(3, H, W)或(H, W, 3)的numpy数组\n",
    "    \n",
    "    返回:\n",
    "    yuv: YUV图像，形状与输入相同\n",
    "    \"\"\"\n",
    "    if len(rgb.shape) == 3 and rgb.shape[0] == 3:\n",
    "        # 形状为(3, H, W)\n",
    "        r, g, b = rgb[0, :, :], rgb[1, :, :], rgb[2, :, :]\n",
    "    elif len(rgb.shape) == 3 and rgb.shape[2] == 3:\n",
    "        # 形状为(H, W, 3)\n",
    "        r, g, b = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]\n",
    "    else:\n",
    "        raise ValueError(\"不支持的图像形状\")\n",
    "    \n",
    "    # 转换公式\n",
    "    y = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    u = -0.147 * r - 0.289 * g + 0.436 * b + 0.5\n",
    "    v = 0.615 * r - 0.515 * g - 0.100 * b + 0.5\n",
    "    \n",
    "    # 确保值在[0, 1]范围内\n",
    "    y = np.clip(y, 0, 1)\n",
    "    u = np.clip(u, 0, 1)\n",
    "    v = np.clip(v, 0, 1)\n",
    "    \n",
    "    if len(rgb.shape) == 3 and rgb.shape[0] == 3:\n",
    "        # 返回形状为(3, H, W)\n",
    "        return np.stack([y, u, v], axis=0)\n",
    "    else:\n",
    "        # 返回形状为(H, W, 3)\n",
    "        return np.stack([y, u, v], axis=2)\n",
    "\n",
    "def compare_SSIM(img1, img2, on_y=False, gray_scale=True, data_range=1.0):\n",
    "    \"\"\"\n",
    "    计算两幅图像之间的结构相似性指数(SSIM)\n",
    "    \n",
    "    参数:\n",
    "    img1, img2: 输入图像\n",
    "    on_y: 是否只计算Y通道(适用于彩色图像)\n",
    "    gray_scale: 是否为灰度图像\n",
    "    data_range: 图像数据的范围(通常为1.0或255)\n",
    "    \"\"\"\n",
    "    if gray_scale:\n",
    "        # 灰度图像直接计算SSIM\n",
    "        return ssim(img1, img2, data_range=data_range)\n",
    "    else:\n",
    "        if on_y:\n",
    "            # 彩色图像但只计算Y通道\n",
    "            if len(img1.shape) == 3 and img1.shape[0] == 3:\n",
    "                # 转换到YUV颜色空间并提取Y通道\n",
    "                img1_y = rgb2yuv(img1)[0, :, :]\n",
    "                img2_y = rgb2yuv(img2)[0, :, :]\n",
    "                return ssim(img1_y, img2_y, data_range=data_range)\n",
    "            else:\n",
    "                # 已经是单通道图像\n",
    "                return ssim(img1, img2, data_range=data_range)\n",
    "        else:\n",
    "            # 计算多通道SSIM\n",
    "            if len(img1.shape) == 3 and img1.shape[0] == 3:\n",
    "                # 对于彩色图像，计算每个通道的SSIM然后取平均\n",
    "                ssim_values = []\n",
    "                for i in range(3):\n",
    "                    ssim_val = ssim(img1[i, :, :], img2[i, :, :], data_range=data_range)\n",
    "                    ssim_values.append(ssim_val)\n",
    "                return np.mean(ssim_values)\n",
    "            else:\n",
    "                # 单通道图像\n",
    "                return ssim(img1, img2, data_range=data_range)"
   ],
   "id": "cea2b92efd9c4bdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_imgs_deblurring(fname, blur_type, noise_sigma,STD_BLUR, DIM_FILTER,plot=False):\n",
    "    \"\"\"  Loads an image, and add gaussian blur\n",
    "    Args: \n",
    "         fname: path to the image\n",
    "         blur_type: 'uniform' or 'gauss'\n",
    "         noise_sigma: noise added after blur\n",
    "         covert2gray: should we convert to gray scale image?\n",
    "         plot: will plot the images\n",
    "    Out:\n",
    "         dictionary of images and dictionary of psnrs\n",
    "    \"\"\"\n",
    "    img_pil, img_np = load_and_crop_image(fname)        \n",
    "    if GRAY_SCALE:\n",
    "        img_np = rgb2gray(img_pil)\n",
    "    kernel = get_h(blur_type,STD_BLUR,DIM_FILTER)\n",
    "    kernel_torch = np_to_torch(kernel)  \n",
    "    blurred = torch_to_np(blur_th(np_to_torch(img_np), kernel_torch))\n",
    "    blurred = np.clip(blurred + np.random.normal(scale=noise_sigma/255., size=blurred.shape), 0, 1).astype(np.float32)\n",
    "    ssim_val = compare_SSIM(img_np, blurred, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n",
    "    \n",
    "    data_dict = { ORIGINAL: Data(img_np), \n",
    "                 CORRUPTED: Data(blurred, \n",
    "                                 compare_PSNR(img_np, blurred, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE),\n",
    "                                 ssim_val) }  # 添加SSIM值\n",
    "    # data_dict = { ORIGINAL: Data(img_np), \n",
    "    #              CORRUPTED: Data(blurred, compare_PSNR(img_np, blurred,   on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)) }\n",
    "    if plot:\n",
    "        plot_dict(data_dict)\n",
    "    return data_dict,kernel_torch"
   ],
   "id": "fa3f81718b7d60d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get the LR and HR images\n",
    "data_dict,kernel_torch = load_imgs_deblurring('datasets/watercastle.png', BLUR_TYPE, NOISE_SIGMA,STD_BLUR, DIM_FILTER,plot=True)"
   ],
   "id": "a2a2b75058166434"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 拉普拉斯核（用于边缘检测，对噪声敏感）\n",
    "lap_kernel = np.array([[1,-2,1], [-2, 4, -2], [1,-2,1]])\n",
    "# 获取退化图像的高和宽\n",
    "h = data_dict[CORRUPTED].img.shape[2]\n",
    "w = data_dict[CORRUPTED].img.shape[1]\n",
    "\n",
    "def estimate_variance(img):\n",
    "    # 用拉普拉斯核对图像卷积，得到边缘响应（含噪声）\n",
    "    out = convolve2d(img, lap_kernel, mode='valid')\n",
    "    # 通过卷积结果的绝对值之和估计噪声方差\n",
    "    out = np.sum(np.abs(out))\n",
    "    out = (out * np.sqrt(0.5 * np.pi) / (6 * (h-2) * (w-2)))  # 归一化\n",
    "    return out\n",
    "\n",
    "\n",
    "print(data_dict[CORRUPTED].img[:,:,:].shape)\n",
    "# 估计噪声标准差（转换为[0,255]范围）\n",
    "NOISE_SIGMA = estimate_variance(data_dict[CORRUPTED].img[0,:,:])*255\n",
    "print(NOISE_SIGMA)"
   ],
   "id": "8f6a03a66709ba74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_network_and_input(img_shape, input_depth=32, pad='reflection',\n",
    "                          upsample_mode='bilinear', use_interpolate=True, align_corners=False,\n",
    "                          act_fun='LeakyReLU', skip_n33d=128, skip_n33u=128, skip_n11=4,\n",
    "                          num_scales=5, downsample_mode='stride', INPUT='noise'):  # 'meshgrid'\n",
    "    \"\"\" Getting the relevant network and network input (based on the image shape and input depth)\n",
    "        We are using the same default params as in DIP article\n",
    "        img_shape - the image shape (ch, x, y)\n",
    "    \"\"\"\n",
    "    n_channels = img_shape[0]\n",
    "    net = skip(input_depth, n_channels,\n",
    "               num_channels_down=[skip_n33d] * num_scales if isinstance(skip_n33d, int) else skip_n33d,\n",
    "               num_channels_up=[skip_n33u] * num_scales if isinstance(skip_n33u, int) else skip_n33u,\n",
    "               num_channels_skip=[skip_n11] * num_scales if isinstance(skip_n11, int) else skip_n11,\n",
    "               upsample_mode=upsample_mode, use_interpolate=use_interpolate, align_corners=align_corners,\n",
    "               downsample_mode=downsample_mode, need_sigmoid=True, need_bias=True, pad=pad, act_fun=act_fun).type(dtype)\n",
    "    net_input = get_noise(input_depth, INPUT, img_shape[1:]).type(dtype).detach()\n",
    "    return net, net_input"
   ],
   "id": "6e5e646746c36ab1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "size = data_dict['Clean'].img.shape\n",
    "h = size[-2]\n",
    "w = size[-1]\n",
    "Dh_psf = np.array([ [0, 0, 0], [1, -1, 0], [0, 0, 0]])\n",
    "Dv_psf = np.array([ [0, 1, 0], [0, -1, 0], [0, 0, 0]])\n",
    "Id_psf = np.array([[1]])\n",
    "\n",
    "Id_DFT = torch.from_numpy(psf2otf(Id_psf, [h,w])).cuda()\n",
    "Dh_DFT = torch.from_numpy(psf2otf(Dh_psf, [h,w])).cuda()\n",
    "Dv_DFT = torch.from_numpy(psf2otf(Dv_psf, [h,w])).cuda()\n",
    "\n",
    "DhT_DFT = torch.conj(Dh_DFT)\n",
    "DvT_DFT = torch.conj(Dv_DFT)\n",
    "\n",
    "\n",
    "#定义散度\n",
    "def div(zx, zy):\n",
    "    [zxx, zxy] = D(zx, Dh_DFT, Dv_DFT)\n",
    "    [zyx, zyy] = D(zy, Dh_DFT, Dv_DFT)\n",
    "    div = zxx + zyy\n",
    "    return div"
   ],
   "id": "8398457424775475"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_via_admm(net, net_input, kernel_torch,y,  noise_lev,tau, org_img=None,                      # y is the noisy image\n",
    "                   plot_array={}, algorithm_name=\"\", admm_iter=5000, save_path=\"\",           # path to save params\n",
    "                   LR=0.001,tao = 0.001,beta = 2,alpha1 = 1,alpha2 = 10,gama = 0.03,w1 = 0.005,sigma1 = 0.03,            # learning rate\n",
    "                   rou=0.0008, LR_x=None, noise_factor=0.033,        #0.033  LR_x needed only if method!=fixed_point\n",
    "                   threshold=40, threshold_step=0.01, increase_reg=0.033):                # increase regularization \n",
    "    \"\"\" training the network using\n",
    "        ## Must Params ##\n",
    "        net                 - the network to be trained\n",
    "        net_input           - the network input\n",
    "        denoiser_function   - an external denoiser function, used as black box, this function\n",
    "                              must get numpy noisy image, and return numpy denoised image\n",
    "        y                   - the noisy image\n",
    "        sigma               - the noise level (int 0-255)\n",
    "        \n",
    "        # optional params #\n",
    "        org_img             - the original image if exist for psnr compare only, or None (default)\n",
    "        plot_array          - prints params at the begging of the training and plot images at the required indices\n",
    "        admm_iter           - total number of admm epoch\n",
    "        LR                  - the lr of the network in admm (step 2)\n",
    "        sigma_f             - the sigma to send the denoiser function\n",
    "        update_iter         - denoised image updated every 'update_iter' iteration\n",
    "        method              - 'fixed_point' or 'grad' or 'mixed' \n",
    "        algorithm_name      - the name that would show up while running, just to know what we are running ;)\n",
    "                \n",
    "        # equation params #  \n",
    "        beta                - regularization parameter (lambda in the article)\n",
    "        mu                  - ADMM parameter\n",
    "        LR_x                - learning rate of the parameter x, needed only if method!=fixed point\n",
    "        # more\n",
    "        noise_factor       - the amount of noise added to the input of the network\n",
    "        threshold          - when the image become close to the noisy image at this psnr\n",
    "        increase_reg       - we going to increase regularization by this amount\n",
    "        threshold_step     - and keep increasing it every step\n",
    "    \"\"\"\n",
    "    # To print\n",
    "    list_psnr=[]\n",
    "    list_ssim=[]\n",
    "    list_stopping=[]\n",
    "\n",
    "    # get optimizer and loss function:\n",
    "    mse = torch.nn.MSELoss().type(dtype)  # using MSE loss\n",
    "    # additional noise added to the input:\n",
    "    net_input_saved = net_input.detach().clone()\n",
    "    noise = net_input.detach().clone()\n",
    "    if org_img is not None: \n",
    "        psnr_y = compare_PSNR(org_img, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)  # get the noisy image psnr\n",
    "        ssim_y = compare_SSIM(org_img, y, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)  # 计算噪声图像的SSIM\n",
    "    # optimizer and scheduler\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)  # using ADAM opt\n",
    "    \n",
    "    y_torch = np_to_torch(y).type(dtype)\n",
    "    x = y.copy()\n",
    "    u   = 0 * y_torch\n",
    "    v1  = 0 * y_torch\n",
    "    v2  = 0 * y_torch\n",
    "    t  = 0 * y_torch\n",
    "    q11  = 0 * y_torch\n",
    "    q12  = 0 * y_torch\n",
    "    q21  = 0 * y_torch\n",
    "    p1  = 0 * y_torch\n",
    "    p2  = 0 * y_torch\n",
    "    # (v1, v2) = np.zeros_like(y), np.zeros_like(y)\n",
    "    # (p1, p2) = np.zeros_like(y), np.zeros_like(y)\n",
    "    # q11 =  np.zeros_like(y)\n",
    "    # q12 = np.zeros_like(y)\n",
    "    # q21 = np.zeros_like(y)\n",
    "    # q22 = np.zeros_like(y)\n",
    "    f_x, avg, avg2, avg3 = x.copy(), np.rint(y), np.rint(y), np.rint(y)\n",
    "    img_queue = queue.Queue()\n",
    "    \n",
    "    #inner_iter=1\n",
    "    [v11, v12] = D(v1, Dh_DFT, Dv_DFT)\n",
    "    [v21, v22] = D(v2, Dh_DFT, Dv_DFT)\n",
    "    for i in range(1, 1 + admm_iter):\n",
    "        \n",
    "        rho = tau*noise_lev*np.sqrt(y.shape[0]*y.shape[1]*y.shape[2] - 1)\n",
    "\n",
    "      # step 1, update network:\n",
    "        optimizer.zero_grad()\n",
    "        net_input = net_input_saved + (noise.normal_() * noise_factor)\n",
    "        out = net(net_input)\n",
    "        out_np = torch_to_np(out)\n",
    "              \n",
    "      # loss:\n",
    "      #   [Dh_out, Dv_out] = D(out, Dh_DFT, Dv_DFT) #computing the gradient\n",
    "      #   Dh_out_np        = torch_to_np(Dh_out)\n",
    "      #   Dv_out_np        = torch_to_np(Dv_out)\n",
    "        loss_y = mse(blur_th(out, kernel_torch), y_torch)\n",
    "        loss_x = mse(out, (t - u).type(dtype))\n",
    "        total_loss = loss_y + rou * loss_x\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "          \n",
    "      # step 2\n",
    "        u = ((u + tao * div(p1, p2) + tao * rou *(out + t )) / (1 + rou * tao)).detach().clone()\n",
    "        [u1, u2] = D(u, Dh_DFT, Dv_DFT)#计算梯度\n",
    "        \n",
    "        # 更新 p\n",
    "        \n",
    "        #计算 梯度u - v\n",
    "        b1 = u1-v1\n",
    "        b2 = u2-v2\n",
    "        mochang1 = torch.sqrt(torch.pow(b1, 2) + torch.pow(b2, 2) )\n",
    "        #计算ε（v）\n",
    "        \n",
    "        \n",
    "        b11 = v11\n",
    "        b12 = 1/2 * (v12 + v21)\n",
    "        b21 = 1/2 * (v12 + v21)\n",
    "        b22 = v22\n",
    "        mochang2 = torch.sqrt(torch.pow(b11, 2) + torch.pow(b12, 2) + torch.pow(b21, 2) + torch.pow(b22, 2))\n",
    "        fenmu = beta+alpha1*mochang1+alpha2*mochang2\n",
    "        cigema = ((beta+1)*alpha1 )/ fenmu\n",
    "        \n",
    "        a1 = p1 + gama * (u1-v1)\n",
    "        a2 = p2 + gama * (u2-v2)\n",
    "        fanshu =  torch.sqrt(torch.pow(a1, 2) + torch.pow(a2, 2) )#计算a1 和 a2 的平方，相加，最后取平方根。\n",
    "        mm = torch.clamp( fanshu / cigema, min=1)\n",
    "        #fanshu 除以 alpha1 的结果，并使用 torch.clamp 函数将结果限制在最小值为 1 的范围内。\n",
    "        p1 = (a1 / mm).detach().clone()\n",
    "        p2 = (a2 / mm).detach().clone()\n",
    "        \n",
    "        v1 = (v1 + w1*(p1+div(q11, q12))).detach().clone()\n",
    "        v2 = (v2 + w1*(p2+div(q21, q22))).detach().clone()\n",
    "\n",
    "    #  epsilon(v)\n",
    "    \n",
    "        [v11, v12] = D(v1, Dh_DFT, Dv_DFT)\n",
    "        [v21, v22] = D(v2, Dh_DFT, Dv_DFT)\n",
    "            \n",
    "    # 更新 q\n",
    "        # [u1, u2] = D(u, Dh_DFT, Dv_DFT)\n",
    "        c1 = u1-v1\n",
    "        c2 = u2-v2\n",
    "        mochang3 = torch.sqrt(torch.pow(c1, 2) + torch.pow(c2, 2) )\n",
    "        c11 = v11\n",
    "        c12 = 1/2 * (v12 + v21)\n",
    "        c21 = 1/2 * (v12 + v21)\n",
    "        c22 = v22\n",
    "        mochang4 = torch.sqrt(torch.pow(c11, 2) + torch.pow(c12, 2) + torch.pow(c21, 2) + torch.pow(c22, 2))\n",
    "        fenmu1 = beta+alpha1*mochang3+alpha2*mochang4\n",
    "        yita = ((beta+1)*alpha2) / fenmu1\n",
    "        a11 = q11 + sigma1 * v11 \n",
    "        a12 = q12 + sigma1 * 1/2 * (v12 + v21)\n",
    "        a21 = q21 + sigma1 * 1/2 * (v12 + v21)\n",
    "        a22 = q22 + sigma1 * v22 \n",
    "\n",
    "        fanshu =  torch.sqrt(torch.pow(a11, 2) + torch.pow(a12, 2) + torch.pow(a21, 2) + torch.pow(a22, 2))\n",
    "        mm = torch.clamp( fanshu / yita, min=1)\n",
    "        q11 = (a11 / mm).detach().clone()\n",
    "        q12 = (a12 / mm).detach().clone()\n",
    "        q21 = (a21 / mm).detach().clone()\n",
    "        q22 = (a22 / mm).detach().clone()\n",
    "\n",
    "    # t\n",
    "        t = (t -u + out).detach().clone() \n",
    "      \n",
    "\n",
    "      # Averaging:\n",
    "        avg = avg * .99 + out_np * .01\n",
    "\n",
    "        stopping = np.sqrt(np.sum(np.square(torch_to_np(blur_th(out.data, kernel_torch))-y)))/ rho \n",
    "        list_stopping.append(stopping)\n",
    "        \n",
    "      # show psnrs: \n",
    "        psnr_noisy = compare_PSNR(out_np, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n",
    "        \n",
    "        if org_img is not None:\n",
    "            psnr_net, psnr_avg = (compare_PSNR(org_img, out_np,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE),\n",
    "                                  compare_PSNR(org_img, avg, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))\n",
    "            ssim_net = compare_SSIM(org_img, out_np, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n",
    "            ssim_avg = compare_SSIM(org_img, avg, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n",
    "            list_psnr.append(psnr_avg)\n",
    "            list_ssim.append(ssim_avg)\n",
    "            print('\\r', algorithm_name, '%04d/%04d Loss %f' % (i, admm_iter, total_loss.item()),\n",
    "                  'psnrs: y: %.2f psnr_noisy: %.2f net: %.2f avg: %.2f' % (psnr_y, psnr_noisy, psnr_net, psnr_avg), \n",
    "                  'ssim: y: %.4f net: %.4f avg: %.4f' % (ssim_y, ssim_net, ssim_avg),  # 添加SSIM输出\n",
    "                  'params: stopping: %.2f' %(stopping), end='')\n",
    "            if i in plot_array:  # plot images\n",
    "                tmp_dict = {'Clean': Data(org_img),\n",
    "                          'Noisy': Data(y, psnr_y, ssim_y),\n",
    "                          'Net': Data(out_np, psnr_net, ssim_net),  \n",
    "                          'avg': Data(avg, psnr_avg, ssim_avg),      \n",
    "                            }\n",
    "                plot_dict(tmp_dict)\n",
    "        else:\n",
    "            print('\\r', algorithm_name, 'iteration %04d/%04d Loss %f' % (i, admm_iter, total_loss.item()), end='')\n",
    "  \n",
    "    return avg,list_psnr,list_ssim,list_stopping"
   ],
   "id": "9f51ca7d50dedfb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_and_plot(name, plot_checkpoints={}):\n",
    "    global data_dict\n",
    "    noise_lev = NOISE_SIGMA/255\n",
    "    tau=1 #lasciare a 1 se ci si fida della stima del rumore fatta dalla funzione considerata\n",
    "    net, net_input = get_network_and_input(img_shape=data_dict[CORRUPTED].img.shape)\n",
    "    denoised_img,list_psnr,list_ssim,list_stopping = train_via_admm(net, net_input, kernel_torch,data_dict[CORRUPTED].img, noise_lev,tau,\n",
    "                                  plot_array=plot_checkpoints, algorithm_name=name,\n",
    "                                  org_img=data_dict[ORIGINAL].img)\n",
    "    # 计算最终SSIM\n",
    "    final_ssim = compare_SSIM(data_dict[ORIGINAL].img, denoised_img, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n",
    "    data_dict[name] = Data(denoised_img, \n",
    "                           compare_PSNR(data_dict[ORIGINAL].img, denoised_img, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE),\n",
    "                           final_ssim)  # 添加SSIM值\n",
    "    # data_dict[name] = Data(denoised_img, compare_PSNR(data_dict[ORIGINAL].img, denoised_img,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))\n",
    "    plot_dict(data_dict)\n",
    "\n",
    "    return denoised_img,list_psnr,list_ssim,list_stopping\n",
    "\n",
    "\n",
    "plot_checkpoints = {1, 10, 50, 100, 250, 500, 2000, 3500, 5000} \n",
    "denoised_img,list_psnr,list_ssim,list_stopping=run_and_plot(DIP_NLM, plot_checkpoints) "
   ],
   "id": "b5ae8c29f24ecc7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
